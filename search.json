[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Notes For Future Flo",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nIf you have two measures of the same confounder, it might be better to only control for the measurement-invariant one.\n\n\n\nmeasurement invariance\n\ncausal inference\n\n\n\nResponse to ‘The 100% CI’ blog post: ‘If you have two measures of the same confounder, you can just include both of them in your regression model.’\n\n\n\n\n\nNov 24, 2025\n\n\nFlorian Pargent\n\n\n\n\n\n\n\n\n\n\n\n\nComputing predictions for multilevel models with the marginaleffects package\n\n\n\nmarginaleffects\n\nbrms\n\nlme4\n\nmultilevel model\n\nestimand\n\n\n\nHow to compute predictions and making inferences for different estimands in Generalized Linear Mixed Models, using the lme4, brms, and marginaleffects R packages.\n\n\n\n\n\nMay 28, 2024\n\n\nFlorian Pargent\n\n\n\n\n\n\n\n\n\n\n\n\nP-value distribution under H0\n\n\n\np-value\n\nstatistical literacy\n\nteaching\n\n\n\nSome basic visualizations to build intuition on why the p-value is uniformly distributed if the null hypothesis is true.\n\n\n\n\n\nMay 19, 2024\n\n\nFlorian Pargent\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "impressum.html",
    "href": "impressum.html",
    "title": "\nImpressum\n",
    "section": "",
    "text": "Impressum\n\n\nDiensteanbieter\n\n\nFlorian Pargent\n\n\nHardenbergstr. 22\n\n\n80992 München\n\n\nDeutschland\n\n\nKontaktmöglichkeiten\n\n\nE-Mail-Adresse: florian.pargent@psy.lmu.de\n\n\nJournalistisch-redaktionelle Angebote\n\n\nInhaltlich verantwortlich: Florian Pargent (Adresse wie oben)\n\n\nErstellt mit kostenlosem Datenschutz-Generator.de von Dr. Thomas Schwenke"
  },
  {
    "objectID": "datenschutz.html",
    "href": "datenschutz.html",
    "title": "\nDatenschutzerklärung\n",
    "section": "",
    "text": "Datenschutzerklärung\n\n\nPräambel\n\n\nMit der folgenden Datenschutzerklärung möchten wir Sie darüber aufklären, welche Arten Ihrer personenbezogenen Daten (nachfolgend auch kurz als “Daten” bezeichnet) wir zu welchen Zwecken und in welchem Umfang verarbeiten. Die Datenschutzerklärung gilt für alle von uns durchgeführten Verarbeitungen personenbezogener Daten, sowohl im Rahmen der Erbringung unserer Leistungen als auch insbesondere auf unseren Webseiten, in mobilen Applikationen sowie innerhalb externer Onlinepräsenzen, wie z.B. unserer Social-Media-Profile (nachfolgend zusammenfassend bezeichnet als “Onlineangebot”).\n\n\nDie verwendeten Begriffe sind nicht geschlechtsspezifisch.\n\n\nStand: 24. Mai 2024\n\n\nInhaltsübersicht\n\n\n\nPräambel\n\n\nVerantwortlicher\n\n\nÜbersicht der Verarbeitungen\n\n\nMaßgebliche Rechtsgrundlagen\n\n\nSicherheitsmaßnahmen\n\n\nAllgemeine Informationen zur Datenspeicherung und Löschung\n\n\nRechte der betroffenen Personen\n\n\nBereitstellung des Onlineangebots und Webhosting\n\n\nBlogs und Publikationsmedien\n\n\nPräsenzen in sozialen Netzwerken (Social Media)\n\n\nPlug-ins und eingebettete Funktionen sowie Inhalte\n\n\n\nVerantwortlicher\n\n\nFlorian PargentHardenbergstr. 2280992 München\n\n\nE-Mail-Adresse: florian.pargent@psy.lmu.de\n\n\nÜbersicht der Verarbeitungen\n\n\nDie nachfolgende Übersicht fasst die Arten der verarbeiteten Daten und die Zwecke ihrer Verarbeitung zusammen und verweist auf die betroffenen Personen.\n\n\nArten der verarbeiteten Daten\n\n\n\nBestandsdaten.\n\n\nKontaktdaten.\n\n\nInhaltsdaten.\n\n\nNutzungsdaten.\n\n\nMeta-, Kommunikations- und Verfahrensdaten.\n\n\nProtokolldaten.\n\n\n\nKategorien betroffener Personen\n\n\n\nNutzer.\n\n\n\nZwecke der Verarbeitung\n\n\n\nKommunikation.\n\n\nSicherheitsmaßnahmen.\n\n\nFeedback.\n\n\nBereitstellung unseres Onlineangebotes und Nutzerfreundlichkeit.\n\n\nInformationstechnische Infrastruktur.\n\n\nÖffentlichkeitsarbeit.\n\n\n\nMaßgebliche Rechtsgrundlagen\n\n\nMaßgebliche Rechtsgrundlagen nach der DSGVO: Im Folgenden erhalten Sie eine Übersicht der Rechtsgrundlagen der DSGVO, auf deren Basis wir personenbezogene Daten verarbeiten. Bitte nehmen Sie zur Kenntnis, dass neben den Regelungen der DSGVO nationale Datenschutzvorgaben in Ihrem bzw. unserem Wohn- oder Sitzland gelten können. Sollten ferner im Einzelfall speziellere Rechtsgrundlagen maßgeblich sein, teilen wir Ihnen diese in der Datenschutzerklärung mit.\n\n\n\nEinwilligung (Art. 6 Abs. 1 S. 1 lit. a) DSGVO) - Die betroffene Person hat ihre Einwilligung in die Verarbeitung der sie betreffenden personenbezogenen Daten für einen spezifischen Zweck oder mehrere bestimmte Zwecke gegeben.\n\n\nBerechtigte Interessen (Art. 6 Abs. 1 S. 1 lit. f) DSGVO) - die Verarbeitung ist zur Wahrung der berechtigten Interessen des Verantwortlichen oder eines Dritten notwendig, vorausgesetzt, dass die Interessen, Grundrechte und Grundfreiheiten der betroffenen Person, die den Schutz personenbezogener Daten verlangen, nicht überwiegen.\n\n\n\nNationale Datenschutzregelungen in Deutschland: Zusätzlich zu den Datenschutzregelungen der DSGVO gelten nationale Regelungen zum Datenschutz in Deutschland. Hierzu gehört insbesondere das Gesetz zum Schutz vor Missbrauch personenbezogener Daten bei der Datenverarbeitung (Bundesdatenschutzgesetz – BDSG). Das BDSG enthält insbesondere Spezialregelungen zum Recht auf Auskunft, zum Recht auf Löschung, zum Widerspruchsrecht, zur Verarbeitung besonderer Kategorien personenbezogener Daten, zur Verarbeitung für andere Zwecke und zur Übermittlung sowie automatisierten Entscheidungsfindung im Einzelfall einschließlich Profiling. Ferner können Landesdatenschutzgesetze der einzelnen Bundesländer zur Anwendung gelangen.\n\n\nHinweis auf Geltung DSGVO und Schweizer DSG: Diese Datenschutzhinweise dienen sowohl der Informationserteilung nach dem Schweizer DSG als auch nach der Datenschutzgrundverordnung (DSGVO). Aus diesem Grund bitten wir Sie zu beachten, dass aufgrund der breiteren räumlichen Anwendung und Verständlichkeit die Begriffe der DSGVO verwendet werden. Insbesondere statt der im Schweizer DSG verwendeten Begriffe „Bearbeitung” von „Personendaten”, “überwiegendes Interesse” und “besonders schützenswerte Personendaten” werden die in der DSGVO verwendeten Begriffe „Verarbeitung” von „personenbezogenen Daten” sowie “berechtigtes Interesse” und “besondere Kategorien von Daten” verwendet. Die gesetzliche Bedeutung der Begriffe wird jedoch im Rahmen der Geltung des Schweizer DSG weiterhin nach dem Schweizer DSG bestimmt.\n\n\nSicherheitsmaßnahmen\n\n\nWir treffen nach Maßgabe der gesetzlichen Vorgaben unter Berücksichtigung des Stands der Technik, der Implementierungskosten und der Art, des Umfangs, der Umstände und der Zwecke der Verarbeitung sowie der unterschiedlichen Eintrittswahrscheinlichkeiten und des Ausmaßes der Bedrohung der Rechte und Freiheiten natürlicher Personen geeignete technische und organisatorische Maßnahmen, um ein dem Risiko angemessenes Schutzniveau zu gewährleisten.\n\n\nZu den Maßnahmen gehören insbesondere die Sicherung der Vertraulichkeit, Integrität und Verfügbarkeit von Daten durch Kontrolle des physischen und elektronischen Zugangs zu den Daten als auch des sie betreffenden Zugriffs, der Eingabe, der Weitergabe, der Sicherung der Verfügbarkeit und ihrer Trennung. Des Weiteren haben wir Verfahren eingerichtet, die eine Wahrnehmung von Betroffenenrechten, die Löschung von Daten und Reaktionen auf die Gefährdung der Daten gewährleisten. Ferner berücksichtigen wir den Schutz personenbezogener Daten bereits bei der Entwicklung bzw. Auswahl von Hardware, Software sowie Verfahren entsprechend dem Prinzip des Datenschutzes, durch Technikgestaltung und durch datenschutzfreundliche Voreinstellungen.\n\n\nSicherung von Online-Verbindungen durch TLS-/SSL-Verschlüsselungstechnologie (HTTPS): Um die Daten der Nutzer, die über unsere Online-Dienste übertragen werden, vor unerlaubten Zugriffen zu schützen, setzen wir auf die TLS-/SSL-Verschlüsselungstechnologie. Secure Sockets Layer (SSL) und Transport Layer Security (TLS) sind die Eckpfeiler der sicheren Datenübertragung im Internet. Diese Technologien verschlüsseln die Informationen, die zwischen der Website oder App und dem Browser des Nutzers (oder zwischen zwei Servern) übertragen werden, wodurch die Daten vor unbefugtem Zugriff geschützt sind. TLS, als die weiterentwickelte und sicherere Version von SSL, gewährleistet, dass alle Datenübertragungen den höchsten Sicherheitsstandards entsprechen. Wenn eine Website durch ein SSL-/TLS-Zertifikat gesichert ist, wird dies durch die Anzeige von HTTPS in der URL signalisiert. Dies dient als ein Indikator für die Nutzer, dass ihre Daten sicher und verschlüsselt übertragen werden.\n\n\nAllgemeine Informationen zur Datenspeicherung und Löschung\n\n\nWir löschen personenbezogene Daten, die wir verarbeiten, gemäß den gesetzlichen Bestimmungen, sobald die zugrundeliegenden Einwilligungen widerrufen werden oder keine weiteren rechtlichen Grundlagen für die Verarbeitung bestehen. Dies betrifft Fälle, in denen der ursprüngliche Verarbeitungszweck entfällt oder die Daten nicht mehr benötigt werden. Ausnahmen von dieser Regelung bestehen, wenn gesetzliche Pflichten oder besondere Interessen eine längere Aufbewahrung oder Archivierung der Daten erfordern.\n\n\nInsbesondere müssen Daten, die aus handels- oder steuerrechtlichen Gründen aufbewahrt werden müssen oder deren Speicherung notwendig ist zur Rechtsverfolgung oder zum Schutz der Rechte anderer natürlicher oder juristischer Personen, entsprechend archiviert werden.\n\n\nUnsere Datenschutzhinweise enthalten zusätzliche Informationen zur Aufbewahrung und Löschung von Daten, die speziell für bestimmte Verarbeitungsprozesse gelten.\n\n\nBei mehreren Angaben zur Aufbewahrungsdauer oder Löschungsfristen eines Datums, ist stets die längste Frist maßgeblich.\n\n\nBeginnt eine Frist nicht ausdrücklich zu einem bestimmten Datum und beträgt sie mindestens ein Jahr, so startet sie automatisch am Ende des Kalenderjahres, in dem das fristauslösende Ereignis eingetreten ist. Im Fall laufender Vertragsverhältnisse, in deren Rahmen Daten gespeichert werden, ist das fristauslösende Ereignis der Zeitpunkt des Wirksamwerdens der Kündigung oder sonstige Beendigung des Rechtsverhältnisses.\n\n\nDaten, die nicht mehr für den ursprünglich vorgesehenen Zweck, sondern aufgrund gesetzlicher Vorgaben oder anderer Gründe aufbewahrt werden, verarbeiten wir ausschließlich zu den Gründen, die ihre Aufbewahrung rechtfertigen.\n\n\nWeitere Hinweise zu Verarbeitungsprozessen, Verfahren und Diensten:\n\n\n\nAufbewahrung und Löschung von Daten: Die folgenden allgemeinen Fristen gelten für die Aufbewahrung und Archivierung nach deutschem Recht:\n\n\n10 Jahre - Aufbewahrungsfrist für Bücher und Aufzeichnungen, Jahresabschlüsse, Inventare, Lageberichte, Eröffnungsbilanz sowie die zu ihrem Verständnis erforderlichen Arbeitsanweisungen und sonstigen Organisationsunterlagen, Buchungsbelege und Rechnungen (§ 147 Abs. 3 i. V. m. Abs. 1 Nr. 1, 4 und 4a AO, § 14b Abs. 1 UStG, § 257 Abs. 1 Nr. 1 u. 4, Abs. 4 HGB).\n\n\n6 Jahre - Übrige Geschäftsunterlagen: empfangene Handels- oder Geschäftsbriefe, Wiedergaben der abgesandten Handels- oder Geschäftsbriefe, sonstige Unterlagen, soweit sie für die Besteuerung von Bedeutung sind, z.B. Stundenlohnzettel, Betriebsabrechnungsbögen, Kalkulationsunterlagen, Preisauszeichnungen, aber auch Lohnabrechnungsunterlagen, soweit sie nicht bereits Buchungsbelege sind und Kassenstreifen (§ 147 Abs. 3 i. V. m. Abs. 1 Nr. 2, 3, 5 AO, § 257 Abs. 1 Nr. 2 u. 3, Abs. 4 HGB).\n\n\n3 Jahre - Daten, die erforderlich sind, um potenzielle Gewährleistungs- und Schadensersatzansprüche oder ähnliche vertragliche Ansprüche und Rechte zu berücksichtigen sowie damit verbundene Anfragen zu bearbeiten, basierend auf früheren Geschäftserfahrungen und üblichen Branchenpraktiken, werden für die Dauer der regulären gesetzlichen Verjährungsfrist von drei Jahren gespeichert (§§ 195, 199 BGB).\n\n\n\n\n\nRechte der betroffenen Personen\n\n\nRechte der betroffenen Personen aus der DSGVO: Ihnen stehen als Betroffene nach der DSGVO verschiedene Rechte zu, die sich insbesondere aus Art. 15 bis 21 DSGVO ergeben:\n\n\n\nWiderspruchsrecht: Sie haben das Recht, aus Gründen, die sich aus Ihrer besonderen Situation ergeben, jederzeit gegen die Verarbeitung der Sie betreffenden personenbezogenen Daten, die aufgrund von Art. 6 Abs. 1 lit. e oder f DSGVO erfolgt, Widerspruch einzulegen; dies gilt auch für ein auf diese Bestimmungen gestütztes Profiling. Werden die Sie betreffenden personenbezogenen Daten verarbeitet, um Direktwerbung zu betreiben, haben Sie das Recht, jederzeit Widerspruch gegen die Verarbeitung der Sie betreffenden personenbezogenen Daten zum Zwecke derartiger Werbung einzulegen; dies gilt auch für das Profiling, soweit es mit solcher Direktwerbung in Verbindung steht.\n\n\nWiderrufsrecht bei Einwilligungen: Sie haben das Recht, erteilte Einwilligungen jederzeit zu widerrufen.\n\n\nAuskunftsrecht: Sie haben das Recht, eine Bestätigung darüber zu verlangen, ob betreffende Daten verarbeitet werden und auf Auskunft über diese Daten sowie auf weitere Informationen und Kopie der Daten entsprechend den gesetzlichen Vorgaben.\n\n\nRecht auf Berichtigung: Sie haben entsprechend den gesetzlichen Vorgaben das Recht, die Vervollständigung der Sie betreffenden Daten oder die Berichtigung der Sie betreffenden unrichtigen Daten zu verlangen.\n\n\nRecht auf Löschung und Einschränkung der Verarbeitung: Sie haben nach Maßgabe der gesetzlichen Vorgaben das Recht, zu verlangen, dass Sie betreffende Daten unverzüglich gelöscht werden, bzw. alternativ nach Maßgabe der gesetzlichen Vorgaben eine Einschränkung der Verarbeitung der Daten zu verlangen.\n\n\nRecht auf Datenübertragbarkeit: Sie haben das Recht, Sie betreffende Daten, die Sie uns bereitgestellt haben, nach Maßgabe der gesetzlichen Vorgaben in einem strukturierten, gängigen und maschinenlesbaren Format zu erhalten oder deren Übermittlung an einen anderen Verantwortlichen zu fordern.\n\n\nBeschwerde bei Aufsichtsbehörde: Sie haben unbeschadet eines anderweitigen verwaltungsrechtlichen oder gerichtlichen Rechtsbehelfs das Recht auf Beschwerde bei einer Aufsichtsbehörde, insbesondere in dem Mitgliedstaat ihres gewöhnlichen Aufenthaltsorts, ihres Arbeitsplatzes oder des Orts des mutmaßlichen Verstoßes, wenn Sie der Ansicht sind, dass die Verarbeitung der Sie betreffenden personenbezogenen Daten gegen die Vorgaben der DSGVO verstößt.\n\n\n\nBereitstellung des Onlineangebots und Webhosting\n\n\nWir verarbeiten die Daten der Nutzer, um ihnen unsere Online-Dienste zur Verfügung stellen zu können. Zu diesem Zweck verarbeiten wir die IP-Adresse des Nutzers, die notwendig ist, um die Inhalte und Funktionen unserer Online-Dienste an den Browser oder das Endgerät der Nutzer zu übermitteln.\n\n\n\nVerarbeitete Datenarten: Nutzungsdaten (z. B. Seitenaufrufe und Verweildauer, Klickpfade, Nutzungsintensität und -frequenz, verwendete Gerätetypen und Betriebssysteme, Interaktionen mit Inhalten und Funktionen); Meta-, Kommunikations- und Verfahrensdaten (z. B. IP-Adressen, Zeitangaben, Identifikationsnummern, beteiligte Personen). Protokolldaten (z.B. Logfiles betreffend Logins oder den Abruf von Daten oder Zugriffszeiten.).\n\n\nBetroffene Personen: Nutzer (z.B. Webseitenbesucher, Nutzer von Onlinediensten).\n\n\nZwecke der Verarbeitung: Bereitstellung unseres Onlineangebotes und Nutzerfreundlichkeit; Informationstechnische Infrastruktur (Betrieb und Bereitstellung von Informationssystemen und technischen Geräten (Computer, Server etc.).). Sicherheitsmaßnahmen.\n\n\nAufbewahrung und Löschung: Löschung entsprechend Angaben im Abschnitt “Allgemeine Informationen zur Datenspeicherung und Löschung”.\n\n\nRechtsgrundlagen: Berechtigte Interessen (Art. 6 Abs. 1 S. 1 lit. f) DSGVO).\n\n\n\nWeitere Hinweise zu Verarbeitungsprozessen, Verfahren und Diensten:\n\n\n\nErhebung von Zugriffsdaten und Logfiles: Der Zugriff auf unser Onlineangebot wird in Form von sogenannten “Server-Logfiles” protokolliert. Zu den Serverlogfiles können die Adresse und der Name der abgerufenen Webseiten und Dateien, Datum und Uhrzeit des Abrufs, übertragene Datenmengen, Meldung über erfolgreichen Abruf, Browsertyp nebst Version, das Betriebssystem des Nutzers, Referrer URL (die zuvor besuchte Seite) und im Regelfall IP-Adressen und der anfragende Provider gehören. Die Serverlogfiles können zum einen zu Sicherheitszwecken eingesetzt werden, z.B. um eine Überlastung der Server zu vermeiden (insbesondere im Fall von missbräuchlichen Angriffen, sogenannten DDoS-Attacken), und zum anderen, um die Auslastung der Server und ihre Stabilität sicherzustellen; Rechtsgrundlagen: Berechtigte Interessen (Art. 6 Abs. 1 S. 1 lit. f) DSGVO). Löschung von Daten: Logfile-Informationen werden für die Dauer von maximal 30 Tagen gespeichert und danach gelöscht oder anonymisiert. Daten, deren weitere Aufbewahrung zu Beweiszwecken erforderlich ist, sind bis zur endgültigen Klärung des jeweiligen Vorfalls von der Löschung ausgenommen.\n\n\n\nBlogs und Publikationsmedien\n\n\nWir nutzen Blogs oder vergleichbare Mittel der Onlinekommunikation und Publikation (nachfolgend “Publikationsmedium”). Die Daten der Leser werden für die Zwecke des Publikationsmediums nur insoweit verarbeitet, als es für dessen Darstellung und die Kommunikation zwischen Autoren und Lesern oder aus Gründen der Sicherheit erforderlich ist. Im Übrigen verweisen wir auf die Informationen zur Verarbeitung der Besucher unseres Publikationsmediums im Rahmen dieser Datenschutzhinweise.\n\n\n\nVerarbeitete Datenarten: Bestandsdaten (z.B. der vollständige Name, Wohnadresse, Kontaktinformationen, Kundennummer, etc.); Kontaktdaten (z.B. Post- und E-Mail-Adressen oder Telefonnummern); Inhaltsdaten (z. B. textliche oder bildliche Nachrichten und Beiträge sowie die sie betreffenden Informationen, wie z. B. Angaben zur Autorenschaft oder Zeitpunkt der Erstellung); Nutzungsdaten (z. B. Seitenaufrufe und Verweildauer, Klickpfade, Nutzungsintensität und -frequenz, verwendete Gerätetypen und Betriebssysteme, Interaktionen mit Inhalten und Funktionen). Meta-, Kommunikations- und Verfahrensdaten (z. B. IP-Adressen, Zeitangaben, Identifikationsnummern, beteiligte Personen).\n\n\nBetroffene Personen: Nutzer (z.B. Webseitenbesucher, Nutzer von Onlinediensten).\n\n\nZwecke der Verarbeitung: Feedback (z.B. Sammeln von Feedback via Online-Formular). Bereitstellung unseres Onlineangebotes und Nutzerfreundlichkeit.\n\n\nAufbewahrung und Löschung: Löschung entsprechend Angaben im Abschnitt “Allgemeine Informationen zur Datenspeicherung und Löschung”.\n\n\nRechtsgrundlagen: Berechtigte Interessen (Art. 6 Abs. 1 S. 1 lit. f) DSGVO).\n\n\n\nPräsenzen in sozialen Netzwerken (Social Media)\n\n\nWir unterhalten Onlinepräsenzen innerhalb sozialer Netzwerke und verarbeiten in diesem Rahmen Nutzerdaten, um mit den dort aktiven Nutzern zu kommunizieren oder Informationen über uns anzubieten.\n\n\nWir weisen darauf hin, dass dabei Nutzerdaten außerhalb des Raumes der Europäischen Union verarbeitet werden können. Hierdurch können sich für die Nutzer Risiken ergeben, weil so zum Beispiel die Durchsetzung der Nutzerrechte erschwert werden könnte.\n\n\nFerner werden die Daten der Nutzer innerhalb sozialer Netzwerke im Regelfall für Marktforschungs- und Werbezwecke verarbeitet. So können beispielsweise anhand des Nutzungsverhaltens und sich daraus ergebender Interessen der Nutzer Nutzungsprofile erstellt werden. Letztere finden möglicherweise wiederum Verwendung, um etwa Werbeanzeigen innerhalb und außerhalb der Netzwerke zu schalten, die mutmaßlich den Interessen der Nutzer entsprechen. Daher werden im Regelfall Cookies auf den Rechnern der Nutzer gespeichert, in denen das Nutzungsverhalten und die Interessen der Nutzer gespeichert werden. Zudem können in den Nutzungsprofilen auch Daten unabhängig der von den Nutzern verwendeten Geräten gespeichert werden (insbesondere, wenn sie Mitglieder der jeweiligen Plattformen und dort eingeloggt sind).\n\n\nFür eine detaillierte Darstellung der jeweiligen Verarbeitungsformen und der Widerspruchsmöglichkeiten (Opt-out) verweisen wir auf die Datenschutzerklärungen und Angaben der Betreiber der jeweiligen Netzwerke.\n\n\nAuch im Fall von Auskunftsanfragen und der Geltendmachung von Betroffenenrechten weisen wir darauf hin, dass diese am effektivsten bei den Anbietern geltend gemacht werden können. Nur Letztere haben jeweils Zugriff auf die Nutzerdaten und können direkt entsprechende Maßnahmen ergreifen und Auskünfte geben. Sollten Sie dennoch Hilfe benötigen, dann können Sie sich an uns wenden.\n\n\n\nVerarbeitete Datenarten: Kontaktdaten (z.B. Post- und E-Mail-Adressen oder Telefonnummern); Inhaltsdaten (z. B. textliche oder bildliche Nachrichten und Beiträge sowie die sie betreffenden Informationen, wie z. B. Angaben zur Autorenschaft oder Zeitpunkt der Erstellung). Nutzungsdaten (z. B. Seitenaufrufe und Verweildauer, Klickpfade, Nutzungsintensität und -frequenz, verwendete Gerätetypen und Betriebssysteme, Interaktionen mit Inhalten und Funktionen).\n\n\nBetroffene Personen: Nutzer (z.B. Webseitenbesucher, Nutzer von Onlinediensten).\n\n\nZwecke der Verarbeitung: Kommunikation; Feedback (z.B. Sammeln von Feedback via Online-Formular). Öffentlichkeitsarbeit.\n\n\nAufbewahrung und Löschung: Löschung entsprechend Angaben im Abschnitt “Allgemeine Informationen zur Datenspeicherung und Löschung”.\n\n\nRechtsgrundlagen: Berechtigte Interessen (Art. 6 Abs. 1 S. 1 lit. f) DSGVO).\n\n\n\nWeitere Hinweise zu Verarbeitungsprozessen, Verfahren und Diensten:\n\n\n\nXing: Soziales Netzwerk; Dienstanbieter: New Work SE, Am Strandkai 1, 20457 Hamburg, Deutschland; Rechtsgrundlagen: Berechtigte Interessen (Art. 6 Abs. 1 S. 1 lit. f) DSGVO); Website: https://www.xing.com/. Datenschutzerklärung: https://privacy.xing.com/de/datenschutzerklaerung.\n\n\n\nPlug-ins und eingebettete Funktionen sowie Inhalte\n\n\nWir binden Funktions- und Inhaltselemente in unser Onlineangebot ein, die von den Servern ihrer jeweiligen Anbieter (nachfolgend als „Drittanbieter” bezeichnet) bezogen werden. Dabei kann es sich zum Beispiel um Grafiken, Videos oder Stadtpläne handeln (nachfolgend einheitlich als „Inhalte” bezeichnet).\n\n\nDie Einbindung setzt immer voraus, dass die Drittanbieter dieser Inhalte die IP-Adresse der Nutzer verarbeiten, da sie ohne IP-Adresse die Inhalte nicht an deren Browser senden könnten. Die IP-Adresse ist damit für die Darstellung dieser Inhalte oder Funktionen erforderlich. Wir bemühen uns, nur solche Inhalte zu verwenden, deren jeweilige Anbieter die IP-Adresse lediglich zur Auslieferung der Inhalte anzuwenden. Drittanbieter können ferner sogenannte Pixel-Tags (unsichtbare Grafiken, auch als „Web Beacons” bezeichnet) für statistische oder Marketingzwecke einsetzen. Durch die „Pixel-Tags” können Informationen, wie etwa der Besucherverkehr auf den Seiten dieser Website, ausgewertet werden. Die pseudonymen Informationen können darüber hinaus in Cookies auf dem Gerät der Nutzer gespeichert werden und unter anderem technische Auskünfte zum Browser und zum Betriebssystem, zu verweisenden Websites, zur Besuchszeit sowie weitere Angaben zur Nutzung unseres Onlineangebots enthalten, aber auch mit solchen Informationen aus anderen Quellen verbunden werden.\n\n\nHinweise zu Rechtsgrundlagen: Sofern wir die Nutzer um ihre Einwilligung in den Einsatz der Drittanbieter bitten, stellt die Rechtsgrundlage der Datenverarbeitung die Erlaubnis dar. Ansonsten werden die Nutzerdaten auf Grundlage unserer berechtigten Interessen (d. h. Interesse an effizienten, wirtschaftlichen und empfängerfreundlichen Leistungen) verarbeitet. In diesem Zusammenhang möchten wir Sie auch auf die Informationen zur Verwendung von Cookies in dieser Datenschutzerklärung hinweisen.\n\n\n\nVerarbeitete Datenarten: Nutzungsdaten (z. B. Seitenaufrufe und Verweildauer, Klickpfade, Nutzungsintensität und -frequenz, verwendete Gerätetypen und Betriebssysteme, Interaktionen mit Inhalten und Funktionen). Meta-, Kommunikations- und Verfahrensdaten (z. B. IP-Adressen, Zeitangaben, Identifikationsnummern, beteiligte Personen).\n\n\nBetroffene Personen: Nutzer (z.B. Webseitenbesucher, Nutzer von Onlinediensten).\n\n\nZwecke der Verarbeitung: Bereitstellung unseres Onlineangebotes und Nutzerfreundlichkeit.\n\n\nAufbewahrung und Löschung: Löschung entsprechend Angaben im Abschnitt “Allgemeine Informationen zur Datenspeicherung und Löschung”. Speicherung von Cookies von bis zu 2 Jahren (Sofern nicht anders angegeben, können Cookies und ähnliche Speichermethoden für einen Zeitraum von zwei Jahren auf den Geräten der Nutzer gespeichert werden.).\n\n\nRechtsgrundlagen: Einwilligung (Art. 6 Abs. 1 S. 1 lit. a) DSGVO). Berechtigte Interessen (Art. 6 Abs. 1 S. 1 lit. f) DSGVO).\n\n\n\nErstellt mit kostenlosem Datenschutz-Generator.de von Dr. Thomas Schwenke"
  },
  {
    "objectID": "posts/001_pvalue-distribution/001_pvalue-distribution.html",
    "href": "posts/001_pvalue-distribution/001_pvalue-distribution.html",
    "title": "P-value distribution under H0",
    "section": "",
    "text": "TipIn this post\n\n\n\nOur students asked us whether there is any good intuition on why the p-value of a hypothesis test has a uniform distribution if the null hypothesis is true. So I hacked up some basic visualizations."
  },
  {
    "objectID": "posts/001_pvalue-distribution/001_pvalue-distribution.html#convince-ourselves-that-the-p-value-is-uniformly-distributed-under-the-null-hypothesis",
    "href": "posts/001_pvalue-distribution/001_pvalue-distribution.html#convince-ourselves-that-the-p-value-is-uniformly-distributed-under-the-null-hypothesis",
    "title": "P-value distribution under H0",
    "section": "Convince ourselves that the p-value is uniformly distributed under the null hypothesis",
    "text": "Convince ourselves that the p-value is uniformly distributed under the null hypothesis\nFirst lets think about the quickest way to convince ourselves that the p-value is in fact uniformly distributed:\n\nAssume we have a test statistic, that is t-distributed under \\(H_0\\). So lets sample some test statistics and plot their distribution:\n\nn &lt;- 10000\nt_stat &lt;- rt(n, df = 10)\nhist(t_stat)\n\n\n\n\n\n\n\n\nFor a left-sided t-test with t-distributed test statistic, the p-value is computed with pt and we can clearly see, that these p-values are uniformly distributed.\n\np_value &lt;- pt(t_stat, df = 10)\nhist(p_value)"
  },
  {
    "objectID": "posts/001_pvalue-distribution/001_pvalue-distribution.html#build-some-intuition-where-the-uniform-distribution-of-the-p-value-is-coming-from",
    "href": "posts/001_pvalue-distribution/001_pvalue-distribution.html#build-some-intuition-where-the-uniform-distribution-of-the-p-value-is-coming-from",
    "title": "P-value distribution under H0",
    "section": "Build some intuition where the uniform distribution of the p-value is coming from",
    "text": "Build some intuition where the uniform distribution of the p-value is coming from\nTo build intuition on why the p-value is uniformly distributed under the null hypothesis, have a look at the following plots 1:\n\n\nCode\npar(mfrow = c(2, 1), mar = c(4, 4, 1, 1))\n\n# t-distribution with df = 1\n\ncurve(pt(x, df = 1), xlab = \"\", ylab = \"p-value\", ylim = c(0,1), xlim = c(-7, 7))\ny_values &lt;- seq(0.05, 0.95, by = 0.05)\nx_values &lt;- qt(y_values, df = 1)\nsegments(x_values, rep(-0.5, length(x_values)), x_values, y_values, col = \"red\", lty = 2)\nsegments(x_values, y_values, rep(-7.5, length(y_values)), y_values, col = \"blue\", lty = 2)\naxis(side = 1, col.axis = \"red\")\naxis(side = 2, col.axis = \"blue\")\n\ncurve(dt(x, df = 1), xlab = \"test statistic\", ylab = \"density\", xlim = c(-7, 7))\nabline(v = x_values, col = \"red\", lty = 2)\naxis(side = 1, col.axis = \"red\")\n\n\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\nPer definition, a left-sided p-value computes the ratio of test statistics that would fall below the currently observed value of the test statistic (always assuming \\(H_0\\) is indeed true). On the top left side in Figure 1 we have divided the range of the p-value between 0 and 1 into equal blue intervals of length 0.05. Per definition, between two blue lines will fall 5% percent of values from the underlying test statistics. To achieve this equal percentage everywhere, the distribution function in the upper plot has to “collect” test statistics from a larger red interval on the bottom axis, when we move away from the mean. Close to the mean, we observe more values of the test statistic (as indicated by the density function in the bottom plot) so the interval that makes up 5% of the whole distribution will be small. In other words, the p-value stretches the range of the test statistics into equal intervals. This can best be seen with the largest red interval in the bottom left. Because test statistics are so rarely observed so far away from the mean, we have to collect values from a very wide range to collect 5% of values for the test statistic.\n\n\n\n\n\n\nNote\n\n\n\nThe technical reason for why the p-value is uniformly distributed under the null hypothesis, is the so-called probability integral transform. From Wikipedia:\n\nSuppose that a random variable \\(X\\) has a continuous distribution for which the cumulative distribution function (CDF) is \\(F_X\\). Then the random variable \\(Y\\) defined as\n\n\n\\(Y := F_X(X)\\)\n\n\nhas a standard uniform distribution.\n\nIn our case, \\(Y\\) is the p-value and \\(X\\) is the test statistic."
  },
  {
    "objectID": "posts/001_pvalue-distribution/001_pvalue-distribution.html#imagine-some-animated-version",
    "href": "posts/001_pvalue-distribution/001_pvalue-distribution.html#imagine-some-animated-version",
    "title": "P-value distribution under H0",
    "section": "Imagine some animated version",
    "text": "Imagine some animated version\nPerhaps at some point I will update the ugly plots and build a small animation:\n\nImagine how it would look like to continuously sample test statistics at the bottom of the lower plot. Most points (i.e., observed values of the test statistic) would appear close to the middle but, we would also get rare points further outside.\nImagine that each point would fly upwards within the red corridor until it hits the curve of the distribution function in the upper plot and then flies left within the corresponding blue corridor.\nImage that all incoming points are collected on the left side of the upper plot and are used to continuously update a histogram with the blue corridor as bars."
  },
  {
    "objectID": "posts/001_pvalue-distribution/001_pvalue-distribution.html#footnotes",
    "href": "posts/001_pvalue-distribution/001_pvalue-distribution.html#footnotes",
    "title": "P-value distribution under H0",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI have used df = 1 here for pedagogical reasons.↩︎"
  },
  {
    "objectID": "posts/002_marginaleffects/002_marginaleffects.html",
    "href": "posts/002_marginaleffects/002_marginaleffects.html",
    "title": "Computing predictions for multilevel models with the marginaleffects package",
    "section": "",
    "text": "TipIn this post\n\n\n\nIn the past, I have used the multcomp package to compute inferences for my statistical models in R. However, the marginaleffects package seems to be the new kid in town, and I wanted to learn how it works. In this post, I tried to familiarize myself with the marginaleffects syntax to compute different statistical estimands for multilevel models fitted with the lme4 and brms packages.\nlibrary(tidyverse)\nlibrary(lme4)\nlibrary(brms)\nlibrary(marginaleffects)"
  },
  {
    "objectID": "posts/002_marginaleffects/002_marginaleffects.html#simulate-multilevel-data",
    "href": "posts/002_marginaleffects/002_marginaleffects.html#simulate-multilevel-data",
    "title": "Computing predictions for multilevel models with the marginaleffects package",
    "section": "\n1 Simulate multilevel data",
    "text": "1 Simulate multilevel data\nI will use simulated data from a Generalized Linear Mixed Model (GLMM) in this post. The simulation code was inspired by the online documentation of the faux R package. For this example, imagine that n_subjects subjects respond to n_items stimuli in a diagnostic decision task. The binary response variable y_bin reflects whether the diagnostic decision is correct or not. For some trials, the participants are presented with advice (advice_present = 1) that should help them making the correct diagnostic decision.\n\nsimulate &lt;- function(n_subjects = 100, n_items = 50,\n  b_0 = 0.8, b_a = 1,\n  sd_u0s = 0.5, sd_u0i = 0.5, sd_u1s = 0.5, ...){\n  require(dplyr)\n  require(faux)\n  # simulate design\n  dat &lt;- add_random(subject = n_subjects, item = n_items) %&gt;%\n    mutate(advice_present = rbinom(n(), 1, prob = 2/3)) %&gt;%\n    # add random effects\n    add_ranef(\"subject\", u0s = sd_u0s) %&gt;%#\n    add_ranef(\"subject\", u1s = sd_u1s) %&gt;%\n    add_ranef(\"item\", u0i = sd_u0i) %&gt;%\n    # compute dependent variable\n    mutate(linpred = b_0 + u0i + u0s +\n        (b_a + u1s) * advice_present) %&gt;%\n    mutate(y_prob = plogis(linpred)) %&gt;%\n    mutate(y_bin = rbinom(n = n(), size = 1, prob = y_prob))\n  dat\n}\n\nset.seed(1)\ndat &lt;- simulate()"
  },
  {
    "objectID": "posts/002_marginaleffects/002_marginaleffects.html#fit-multilevel-models",
    "href": "posts/002_marginaleffects/002_marginaleffects.html#fit-multilevel-models",
    "title": "Computing predictions for multilevel models with the marginaleffects package",
    "section": "\n2 Fit multilevel models",
    "text": "2 Fit multilevel models\nI will fit a multilevel model with both the lme4 and the brms package. The specified model is equal to the true model from which the data have been simulated.\n\nf &lt;- y_bin ~ 1 + advice_present +\n  (1 + advice_present || subject) + (1|item)\n\nfit_lme4 &lt;- glmer(f, data = dat, family = \"binomial\")\nset.seed(1)\nfit_brms &lt;- brm(f, data = dat, family = \"bernoulli\", \n  backend = \"cmdstanr\",\n  chains = 4, cores = 4)\n\nRunning MCMC with 4 parallel chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 4 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 3 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 1 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 3 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 1 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 2 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 3 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 4 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 1 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 2 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 3 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 4 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 3 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 4 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 2 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 3 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 4 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 1 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 2 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 3 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 4 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 4 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 2 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 3 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 1 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 4 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 3 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 1 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 4 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 4 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 2 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 4 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 2 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 4 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 3 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 4 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 2 finished in 35.7 seconds.\nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 35.8 seconds.\nChain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 4 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 1 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 37.4 seconds.\nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 38.2 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 36.8 seconds.\nTotal execution time: 38.3 seconds.\n\n\n\nsummary(fit_lme4)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: y_bin ~ 1 + advice_present + (1 + advice_present || subject) +  \n    (1 | item)\n   Data: dat\n\n     AIC      BIC   logLik deviance df.resid \n  4997.9   5030.5  -2494.0   4987.9     4995 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-5.4937  0.2292  0.3969  0.5510  1.4685 \n\nRandom effects:\n Groups    Name           Variance Std.Dev.\n subject   (Intercept)    0.2173   0.4661  \n subject.1 advice_present 0.2519   0.5018  \n item      (Intercept)    0.1949   0.4415  \nNumber of obs: 5000, groups:  subject, 100; item, 50\n\nFixed effects:\n               Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)     0.75270    0.09540    7.89 3.03e-15 ***\nadvice_present  1.02600    0.09085   11.29  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr)\nadvic_prsnt -0.339\n\n\n\nsummary(fit_brms)\n\n Family: bernoulli \n  Links: mu = logit \nFormula: y_bin ~ 1 + advice_present + (1 + advice_present || subject) + (1 | item) \n   Data: dat (Number of observations: 5000) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nMultilevel Hyperparameters:\n~item (Number of levels: 50) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.46      0.06     0.35     0.60 1.00     1318     1884\n\n~subject (Number of levels: 100) \n                   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)          0.48      0.07     0.36     0.62 1.01     1248     2241\nsd(advice_present)     0.53      0.10     0.33     0.72 1.00      899     1800\n\nRegression Coefficients:\n               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept          0.75      0.10     0.56     0.94 1.00     1682     2416\nadvice_present     1.03      0.10     0.85     1.23 1.00     2441     2573\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nWhen looking at the model outputs, we can see that both models have very similar parameter estimates, and parameter estimates closely match the true values we specified in the simulation. The diagnostics of the brms model (Rhats &lt; 0, decent ESS, and no divergent transitions) suggest that the model is identified and has successfully converged, which is what we expect when fitting the true model to a large enough sample."
  },
  {
    "objectID": "posts/002_marginaleffects/002_marginaleffects.html#estimate-different-contrasts-with-marginaleffects",
    "href": "posts/002_marginaleffects/002_marginaleffects.html#estimate-different-contrasts-with-marginaleffects",
    "title": "Computing predictions for multilevel models with the marginaleffects package",
    "section": "\n3 Estimate different contrasts with marginaleffects",
    "text": "3 Estimate different contrasts with marginaleffects\nIn the following sections, I compute predictions from these models with the marginaleffects package and estimate contrasts for different estimands. There are usually several different ways how to compute the same estimates with marginaleffects, and I will convince myself that they produce similar results. Great resources on these topics are the documentation of the marginaleffects package, as well as the excellent blog-posts (1, 2, 3) by Andrew Heiss.\n\n3.1 Some important function arguments and options in marginaleffects\n\n\n\n\n\n\nImportant\n\n\n\nWhen using the datagrid function inside one of the many marginaleffects functions, be aware that by default all variables not explicitly specified are set to the mean or mode (depending on the variable type). Better check the result of datagrid to make sure you know which predictor values your predictions are actually based on!\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen using type = response in marginaleffects for multilevel models fitted with lme4 or brms, this will produce estimates for the conditional expected value of the response \\(E(Y|x, u)\\) (and does not simulate individual response values from the posterior predictive distribution).\n\n\n\n\n\n\n\n\nImportant\n\n\n\nBy default, marginaleffects averages the posterior draws of brms models using the median. However, we might prefer using the mean to assure that the order of aggregation does not matter.\n\noptions(marginaleffects_posterior_center = mean)\noptions(marginaleffects_posterior_interval = \"eti\")\n\nThe other option specifies the type of posterior intervals (equal-tailed intervals vs. highest density intervals). We use the default \"eti\" but list this option here as a reminder that it exist.\n\n\n\n3.2 Treatment effect for an average person and an average item\nEstimand:\n\\[\n\\begin{aligned}\n& P(Y = 1 | advice\\_present = 1, u_{0s} = 0, u_{1s} = 0, u_{0i} = 0) \\\\\n& \\quad - P(Y = 1 | advice\\_present = 0, u_{0s} = 0, u_{1s} = 0, u_{0i} = 0)\n\\end{aligned}\n\\]\n\n3.2.1 lme4\n\n\n\n\n\n\nImportant\n\n\n\nThe option re.form = NA specifies that all random effects are set to 0 when computing predictions. The option re.form = NULL specifies that all random effects are always included.\n\n\n\n\nOption 1\nOption 2\nOption 3\nOption 4\n\n\n\n\navg_predictions(fit_lme4, \n  variables = list(advice_present = 0:1), \n  re.form = NA, type = \"response\") %&gt;% \n  hypotheses(hypothesis = c(\"b2 - b1 = 0\"))\n\n\n    Term Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 %\n b2-b1=0    0.176     0.0166 10.6   &lt;0.001 84.8 0.143  0.208\n\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\n\n\n\navg_comparisons(fit_lme4, \n  variables = \"advice_present\", \n  re.form = NA, type = \"response\")\n\n\n           Term          Contrast Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 %\n advice_present mean(1) - mean(0)    0.176     0.0166 10.6   &lt;0.001 84.8 0.143\n 97.5 %\n  0.208\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\n\n\n\npredictions(fit_lme4,\n  newdata = datagrid(advice_present = 0:1),\n  re.form = NA, type = \"response\") %&gt;% \n  hypotheses(hypothesis = c(\"b2 - b1 = 0\"))\n\n\n    Term Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 %\n b2-b1=0    0.176     0.0166 10.6   &lt;0.001 84.8 0.143  0.208\n\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\n\n\n\ncomparisons(fit_lme4,\n  newdata = datagrid(advice_present = 1),\n  re.form = NA, type = \"response\")\n\n\n           Term Contrast advice_present Estimate Std. Error    z Pr(&gt;|z|)    S\n advice_present    1 - 0              1    0.176     0.0166 10.6   &lt;0.001 84.8\n 2.5 % 97.5 %    subject   item\n 0.143  0.208 subject001 item01\n\nColumns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, advice_present, predicted_lo, predicted_hi, predicted, subject, item, y_bin \nType:  response \n\n\n\n\n\n\n3.2.2 brms\n\n\n\n\n\n\nImportant\n\n\n\nThe option re_formula = NA specifies that all random effects are set to 0 when computing predictions. The option re_formula = NULL specifies that all random effects are always included.\n\n\n\n\nOption 1\nOption 2\nOption 3\nOption 4\n\n\n\n\navg_predictions(fit_brms, \n  variables = list(advice_present = 0:1), \n  re_formula = NA, type = \"response\") %&gt;% \n  hypotheses(hypothesis = c(\"b2 - b1 = 0\"))\n\n\n    Term Estimate 2.5 % 97.5 %\n b2-b1=0    0.177 0.144   0.21\n\nColumns: term, estimate, conf.low, conf.high \nType:  response \n\n\n\n\n\navg_comparisons(fit_brms, \n  variables = \"advice_present\", \n  re_formula = NA, type = \"response\")\n\n\n           Term          Contrast Estimate 2.5 % 97.5 %\n advice_present mean(1) - mean(0)    0.177 0.144   0.21\n\nColumns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx \nType:  response \n\n\n\n\n\npredictions(fit_brms,\n  newdata = datagrid(advice_present = 0:1),\n  re_formula = NA, type = \"response\") %&gt;% \n  hypotheses(hypothesis = c(\"b2 - b1 = 0\"))\n\n\n    Term Estimate 2.5 % 97.5 %\n b2-b1=0    0.177 0.144   0.21\n\nColumns: term, estimate, conf.low, conf.high \nType:  response \n\n\n\n\n\ncomparisons(fit_brms,\n  newdata = datagrid(advice_present = 1),\n  re_formula = NA, type = \"response\")\n\n\n           Term Contrast advice_present Estimate 2.5 % 97.5 %    subject   item\n advice_present    1 - 0              1    0.177 0.144   0.21 subject001 item01\n\nColumns: rowid, term, contrast, estimate, conf.low, conf.high, advice_present, predicted_lo, predicted_hi, predicted, tmp_idx, subject, item, y_bin \nType:  response \n\n\n\n\n\n\n3.3 Treatment effect averaged across the actually observed persons and items\nEstimand:\n\\[\n\\begin{aligned}\n\\frac{1}{S \\cdot I} \\sum_{s}  \\sum_{i} & \\quad P(Y = 1 | advice\\_present = 1, u_{0s}, u_{1s}, u_{0i}) \\\\\n& \\quad - P(Y = 1 | advice\\_present = 0, u_{0s}, u_{1s}, u_{0i})\n\\end{aligned}\n\\]\n\n3.3.1 lme4\n\n\nOption 1\nOption 2\n\n\n\n\navg_predictions(fit_lme4, \n  newdata = datagrid(advice_present = 0:1, subject = unique, item = unique),\n  by = \"advice_present\",\n  re.form = NULL, type = \"response\") %&gt;% \n  hypotheses(hypothesis = c(\"b2 - b1 = 0\"))\n\nWarning: For this model type, `marginaleffects` only takes into account the\n  uncertainty in fixed-effect parameters. You can use the `re.form=NA`\n  argument to acknowledge this explicitly and silence this warning.\nWarning: For this model type, `marginaleffects` only takes into account the\n  uncertainty in fixed-effect parameters. You can use the `re.form=NA`\n  argument to acknowledge this explicitly and silence this warning.\nWarning: For this model type, `marginaleffects` only takes into account the\n  uncertainty in fixed-effect parameters. You can use the `re.form=NA`\n  argument to acknowledge this explicitly and silence this warning.\n\n\n\n    Term Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 %\n b2-b1=0    0.167     0.0162 10.3   &lt;0.001 80.1 0.135  0.199\n\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\n\n\n\navg_comparisons(fit_lme4, \n  variables = \"advice_present\", \n  re.form = NULL, type = \"response\")\n\nWarning: For this model type, `marginaleffects` only takes into account the\n  uncertainty in fixed-effect parameters. You can use the `re.form=NA`\n  argument to acknowledge this explicitly and silence this warning.\n\n\n\n           Term          Contrast Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 %\n advice_present mean(1) - mean(0)    0.167     0.0162 10.3   &lt;0.001 80.1 0.135\n 97.5 %\n  0.199\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\n\n\n\n\n3.3.2 brms\n\n\nOption 1\nOption 2\n\n\n\n\navg_predictions(fit_brms, \n  newdata = datagrid(advice_present = 0:1, subject = unique, item = unique),\n  by = \"advice_present\",\n  re_formula = NULL, type = \"response\") %&gt;% \n  hypotheses(hypothesis = c(\"b2 - b1 = 0\"))\n\n\n    Term Estimate 2.5 % 97.5 %\n b2-b1=0    0.164 0.139   0.19\n\nColumns: term, estimate, conf.low, conf.high \nType:  response \n\n\n\n\n\navg_comparisons(fit_brms, \n  variables = \"advice_present\", \n  re_formula = NULL, type = \"response\")\n\n\n           Term          Contrast Estimate 2.5 % 97.5 %\n advice_present mean(1) - mean(0)    0.164 0.139   0.19\n\nColumns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx \nType:  response \n\n\n\n\n\n\n3.4 Treatment effect averaged across new persons and new items\nEstimand:\n\\[\n\\begin{aligned}\n\\frac{1}{S_{new} \\cdot I_{new}} \\sum_{s_{new}}  \\sum_{i_{new}} & \\quad P(Y = 1 | advice\\_present = 1, u_{0s_{new}}, u_{1s_{new}}, u_{0i_{new}}) \\\\\n& \\quad - P(Y = 1 | advice\\_present = 0, u_{0s_{new}}, u_{1s_{new}}, u_{0i_{new}})\n\\end{aligned}\n\\]\n\n3.4.1 lme4\n\n\n\n\n\n\nWarning\n\n\n\nThis cannot actually be done with lme4, which cannot sample new subjects or items (at least not with its predict function; it would work with the simulatefunction in lme4, which cannot be used by the marginaleffects package)! The code below produces the same results as the lme4 estimates for the Treatment effect for an average person and an average item!\n\n\n\n\nOption 1\nOption 2\n\n\n\n\navg_predictions(fit_lme4, \n  newdata = datagrid(advice_present = 0:1, subject = -1:-50, item = -1:-20),\n  by = \"advice_present\",\n  re.form = NULL, allow.new.levels = TRUE, \n  type = \"response\") %&gt;% \n  hypotheses(hypothesis = c(\"b2 - b1 = 0\"))\n\nWarning: For this model type, `marginaleffects` only takes into account the\n  uncertainty in fixed-effect parameters. You can use the `re.form=NA`\n  argument to acknowledge this explicitly and silence this warning.\nWarning: For this model type, `marginaleffects` only takes into account the\n  uncertainty in fixed-effect parameters. You can use the `re.form=NA`\n  argument to acknowledge this explicitly and silence this warning.\nWarning: For this model type, `marginaleffects` only takes into account the\n  uncertainty in fixed-effect parameters. You can use the `re.form=NA`\n  argument to acknowledge this explicitly and silence this warning.\n\n\n\n    Term Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 %\n b2-b1=0    0.176     0.0166 10.6   &lt;0.001 84.8 0.143  0.208\n\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\n\n\n\navg_comparisons(fit_lme4,\n  variables = \"advice_present\",\n  newdata = datagrid(advice_present = 0:1, subject = -1:-50, item = -1:-20),\n  re.form = NULL, allow.new.levels = TRUE, \n  type = \"response\")\n\nWarning: For this model type, `marginaleffects` only takes into account the\n  uncertainty in fixed-effect parameters. You can use the `re.form=NA`\n  argument to acknowledge this explicitly and silence this warning.\n\n\n\n           Term          Contrast Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 %\n advice_present mean(1) - mean(0)    0.176     0.0166 10.6   &lt;0.001 84.8 0.143\n 97.5 %\n  0.208\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\n\n\n\n\n3.4.2 brms\n\n\n\n\n\n\nImportant\n\n\n\nThe option sample_new_levels = \"gaussian\" specifies that for new factor levels, random effects are drawn from the estimated (multivariate) normal distribution of random effects. Note that this setting is not the default! Also note that allow_new_levels = TRUE will make the brms predictions for new levels non-deterministic!\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe following two options produce slightly different results, and I currently do not know why! It might only be randomness introduced by different seeds.\n\n\n\n\nOption 1\nOption 2\n\n\n\n\nset.seed(1)\navg_predictions(fit_brms, \n  newdata = datagrid(advice_present = 0:1, subject = -1:-50, item = -1:-20),\n  by = \"advice_present\",\n  re_formula = NULL, allow_new_levels = TRUE, sample_new_levels = \"gaussian\", \n  type = \"response\") %&gt;% \n  hypotheses(hypothesis = c(\"b2 - b1 = 0\"))\n\n\n    Term Estimate 2.5 % 97.5 %\n b2-b1=0    0.162 0.121  0.203\n\nColumns: term, estimate, conf.low, conf.high \nType:  response \n\n\n\n\n\nset.seed(1)\navg_comparisons(fit_brms,\n  variables = \"advice_present\",\n  newdata = datagrid(advice_present = 0:1, subject = -1:-50, item = -1:-20),\n  re_formula = NULL, allow_new_levels = TRUE, sample_new_levels = \"gaussian\", \n  type = \"response\")\n\n\n           Term          Contrast Estimate 2.5 % 97.5 %\n advice_present mean(1) - mean(0)    0.163 0.122  0.203\n\nColumns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx \nType:  response \n\n\n\n\n\n\n3.5 Treatment effect averaged across new persons but the actually observed items\nEstimand:\n\\[\n\\begin{aligned}\n\\frac{1}{S_{new} \\cdot I} \\sum_{s_{new}}  \\sum_{i} & \\quad P(Y = 1 | advice\\_present = 1, u_{0s_{new}}, u_{1s_{new}}, u_{0i}) \\\\\n& \\quad - P(Y = 1 | advice\\_present = 0, u_{0s_{new}}, u_{1s_{new}}, u_{0i})\n\\end{aligned}\n\\]\n\n3.5.1 lme4\n\n\n\n\n\n\nWarning\n\n\n\nBecause lme4 cannot sample new levels, what it actually does for a new subject is to set all random effects for the subject to 0.\n\n\n\n\nOption 1\nOption 2\n\n\n\n\navg_predictions(fit_lme4, \n  newdata = datagrid(advice_present = 0:1, subject = -1:-50, item = unique),\n  by = \"advice_present\",\n  re.form = NULL, allow.new.levels = TRUE, \n  type = \"response\") %&gt;% \n  hypotheses(hypothesis = c(\"b2 - b1 = 0\"))\n\nWarning: For this model type, `marginaleffects` only takes into account the\n  uncertainty in fixed-effect parameters. You can use the `re.form=NA`\n  argument to acknowledge this explicitly and silence this warning.\nWarning: For this model type, `marginaleffects` only takes into account the\n  uncertainty in fixed-effect parameters. You can use the `re.form=NA`\n  argument to acknowledge this explicitly and silence this warning.\nWarning: For this model type, `marginaleffects` only takes into account the\n  uncertainty in fixed-effect parameters. You can use the `re.form=NA`\n  argument to acknowledge this explicitly and silence this warning.\n\n\n\n    Term Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 %\n b2-b1=0    0.177     0.0164 10.8   &lt;0.001 87.7 0.145  0.209\n\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\n\n\n\navg_comparisons(fit_lme4,\n  variables = \"advice_present\",\n  newdata = datagrid(advice_present = 0:1, subject = -1:-50, item = unique),\n  re.form = NULL, allow.new.levels = TRUE, \n  type = \"response\")\n\nWarning: For this model type, `marginaleffects` only takes into account the\n  uncertainty in fixed-effect parameters. You can use the `re.form=NA`\n  argument to acknowledge this explicitly and silence this warning.\n\n\n\n           Term          Contrast Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 %\n advice_present mean(1) - mean(0)    0.177     0.0164 10.8   &lt;0.001 87.7 0.145\n 97.5 %\n  0.209\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\n\n\n\n\n3.5.2 brms\n\n\n\n\n\n\nWarning\n\n\n\nThe following two options produce slightly different results, and I currently do not know why! It might only be randomness introduced by different seeds.\n\n\n\n\nOption 1\nOption 2\n\n\n\n\nset.seed(1)\navg_predictions(fit_brms, \n  newdata = datagrid(advice_present = 0:1, subject = -1:-50, item = unique),\n  by = \"advice_present\",\n  re_formula = NULL, allow_new_levels = TRUE, sample_new_levels = \"gaussian\", \n  type = \"response\") %&gt;% \n  hypotheses(hypothesis = c(\"b2 - b1 = 0\"))\n\n\n    Term Estimate 2.5 % 97.5 %\n b2-b1=0    0.163 0.126  0.199\n\nColumns: term, estimate, conf.low, conf.high \nType:  response \n\n\n\n\n\nset.seed(1)\navg_comparisons(fit_brms,\n  variables = \"advice_present\",\n  newdata = datagrid(advice_present = 0:1, subject = -1:-50, item = unique),\n  re_formula = NULL, allow_new_levels = TRUE, sample_new_levels = \"gaussian\", \n  type = \"response\")\n\n\n           Term          Contrast Estimate 2.5 % 97.5 %\n advice_present mean(1) - mean(0)    0.163 0.125  0.198\n\nColumns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx \nType:  response"
  },
  {
    "objectID": "posts/003_mi-response_to_100_ci/003_mi-response_to_100_ci.html",
    "href": "posts/003_mi-response_to_100_ci/003_mi-response_to_100_ci.html",
    "title": "If you have two measures of the same confounder, it might be better to only control for the measurement-invariant one.",
    "section": "",
    "text": "TipIn this post\n\n\n\nIn an interesting post on ‘The 100% CI’ blog titled ‘If you have two measures of the same confounder, you can just include both of them in your regression model’, Julia Rohrer (JR) discussed a toy example in which two independent measures of a latent confounder are available.\nIn this post, I present an extended scenario where one measure of the latent confounder is causally affected by the treatment (i.e., measurement invariance does not hold for this indicator) while the other measure is not. I show by simulation that in this case, it can be better to only use the measurement-invariant measure when controlling for the latent confounder."
  },
  {
    "objectID": "posts/003_mi-response_to_100_ci/003_mi-response_to_100_ci.html#reproduce-julia-rohrers-simulated-scenario",
    "href": "posts/003_mi-response_to_100_ci/003_mi-response_to_100_ci.html#reproduce-julia-rohrers-simulated-scenario",
    "title": "If you have two measures of the same confounder, it might be better to only control for the measurement-invariant one.",
    "section": "Reproduce Julia Rohrer’s simulated scenario",
    "text": "Reproduce Julia Rohrer’s simulated scenario\nBefore playing around with alternative scenarios, I wanted to reproduce JR’s simulation results to make sure that we are on the same page. I reprogrammed her simulation based on the DAG in the original blog post, fitted linear models controlling either for both measures of the confound or only for the indicator with the highest loading on the latent confounder (Covariate 2).\n\nCodeR &lt;- 10000\nn &lt;- 200\nset.seed(42)\nsim1 &lt;- replicate(R, expr = {\n  true_confound &lt;- rnorm(n)\n  X &lt;- 0.5*true_confound + rnorm(n)\n  Y &lt;- 1*true_confound + 0.3*X + rnorm(n)\n  covariate1 &lt;- 1*true_confound + rnorm(n)\n  covariate2 &lt;- 2*true_confound + rnorm(n)\n  mod_ctrl_both &lt;- lm(Y ~ X + covariate1 + covariate2)\n  mod_ctrl_cov2 &lt;- lm(Y ~ X + covariate2)\n  c(est_ctrl_both = coef(mod_ctrl_both)[\"X\"],\n    est_ctrl_cov2 = coef(mod_ctrl_cov2)[\"X\"])})\n\nM_est_ctrl_both_sim1 &lt;- mean(sim1[\"est_ctrl_both.X\",])\nM_est_ctrl_cov2_sim1 &lt;- mean(sim1[\"est_ctrl_cov2.X\",])\nRMSE_ctrl_both_sim1 &lt;- sqrt(mean((sim1[\"est_ctrl_both.X\",] - 0.3)^2))\nRMSE_ctrl_cov2_sim1 &lt;- sqrt(mean((sim1[\"est_ctrl_cov2.X\",] - 0.3)^2))\n\n\nMy estimates are very similar to the original blog post:\nThe average estimate for the causal effect of X on Y from the model controlling for both measures (\\(M_{est} = 0.380\\)) is closer to the true value of 0.3 than the estimate from the model controlling only for Covariate 2 (\\(M_{est} = 0.395\\)). The RMSE values are also very similar to JR’s results with \\(RMSE = 0.110\\) when controlling for both and \\(RMSE = 0.122\\) when controlling only for Covariate 2."
  },
  {
    "objectID": "posts/003_mi-response_to_100_ci/003_mi-response_to_100_ci.html#simulate-extended-scenario-in-which-measurement-invariance-does-not-hold-for-covariate-1",
    "href": "posts/003_mi-response_to_100_ci/003_mi-response_to_100_ci.html#simulate-extended-scenario-in-which-measurement-invariance-does-not-hold-for-covariate-1",
    "title": "If you have two measures of the same confounder, it might be better to only control for the measurement-invariant one.",
    "section": "Simulate extended scenario in which measurement invariance does not hold for Covariate 1",
    "text": "Simulate extended scenario in which measurement invariance does not hold for Covariate 1\nI have recently thought a lot about causal perspectives on measurement invariance (Sterner et al. 2024), and I know that JR has also worked on that topic (Rohrer and Paulewicz 2025). So when I read JR’s blog post (which focused on multicollinearity and not measurement invariance), I was immediately asking myself under which circumstances the recommendation to control for both covariates would not be valid. My intuition was that for measures of the true confounder that are not measurement-invariant (i.e., indicators that are also causally affected by other variables than the latent confounder), it should be possible to construct scenarios in which the non-invariant measures should better not be used to control for the confounder.\nOne interesting scenario I came up with is when a measure of the True confound is also causally affected by the treatment. In JR’s toy example, X is math self-concept, Y is school grades, and the True confound is cognitive abilities. A (hopefully) somewhat plausible case based on the original example might be that Covariate 1 is a numeric power test from an IQ test battery (i.e., a test in which participants have no time limit to complete rather difficult tasks). In contrast, Covariate 2 is a non-numeric speed test from the same IQ test battery (i.e., a test in which participants must complete as many rather simple tasks as possible in limited time). For the sake of the argument, let’s assume that because the test represented by Covariate 2 does not look like a math problem, the score will not be directly affected by the participants’ math self-concept. However, the test represented by Covariate 1 looks like a math problem, thus participants with a low math self-concept get discouraged, tend to give up early to find the right solution, and achieve lower test scores.\nIn line with this hypothetical scenario, I have simulated data according to the extended data-generating process displayed in Figure 1.\n\n\n\n\n\nFigure 1: Extended DAG adapted from JR’s blog post (figure copied from the original post; changes marked in red). In the extended data-generating process, Covariate 1 is also affected by X, while Covariate 2 remains a measurement-invariant measure that is only affected by the True confound.\n\n\n\nCodeR &lt;- 10000\nn &lt;- 200\nset.seed(42)\nsim2 &lt;- replicate(R, expr = {\n  true_confound &lt;- rnorm(n)\n  X &lt;- 0.5*true_confound + rnorm(n)\n  Y &lt;- 1*true_confound + 0.3*X + rnorm(n)\n  covariate1 &lt;- 1*true_confound + 1.5*X + rnorm(n) # add path: X -&gt; covariate1\n  covariate2 &lt;- 2*true_confound + rnorm(n)\n  mod_ctrl_both &lt;- lm(Y ~ X + covariate1 + covariate2)\n  mod_ctrl_cov2 &lt;- lm(Y ~ X + covariate2)\n  c(est_ctrl_both = coef(mod_ctrl_both)[\"X\"],\n    est_ctrl_cov2 = coef(mod_ctrl_cov2)[\"X\"])})\n\nM_est_ctrl_both_sim2 &lt;- mean(sim2[\"est_ctrl_both.X\",])\nM_est_ctrl_cov2_sim2 &lt;- mean(sim2[\"est_ctrl_cov2.X\",])\nRMSE_ctrl_both_sim2 &lt;- sqrt(mean((sim2[\"est_ctrl_both.X\",] - 0.3)^2))\nRMSE_ctrl_cov2_sim2 &lt;- sqrt(mean((sim2[\"est_ctrl_cov2.X\",] - 0.3)^2))\n\n\nWith the extended data-generating process, the results change:\nThe average estimate for the causal effect of X on Y from the model controlling for both measures (\\(M_{est} = 0.138\\)) is now further away from the true value of 0.3 than the estimate from the model controlling only for Covariate 2 (\\(M_{est} = 0.395\\)). The RMSE values are now \\(RMSE = 0.210\\) when controlling for both and \\(RMSE = 0.122\\) when controlling only for Covariate 2."
  },
  {
    "objectID": "posts/003_mi-response_to_100_ci/003_mi-response_to_100_ci.html#rethink-recommendation-to-control-for-all-available-measures-of-a-latent-confounder",
    "href": "posts/003_mi-response_to_100_ci/003_mi-response_to_100_ci.html#rethink-recommendation-to-control-for-all-available-measures-of-a-latent-confounder",
    "title": "If you have two measures of the same confounder, it might be better to only control for the measurement-invariant one.",
    "section": "Rethink recommendation to control for all available measures of a latent confounder",
    "text": "Rethink recommendation to control for all available measures of a latent confounder\nWith the extended data-generating process, JR’s blog title …\n\nIf you have two measures of the same confounder, you can just include both of them in your regression model\n\n… seems not always to be good advice. Instead, it might be better to only control for “clean” measurement-invariant measures of the True confound, which in my scenario is Covariate 2.\nHowever, whether controlling for both measures actually yields a worse result than only controlling for Covariate 2 depends on the actual size of all path coefficients in the data-generating process. That is because in the current DAG, the estimate for the causal effect of X on Y is biased for two different reasons: On the one hand, we have “measurement bias”, because we must control for the True confound but can only do so using imperfect indicators (Covariates 1 and 2). As long as we have only measurement-invariant indicators (like in the original scenario), using more of them in our regression model should be a good idea because we then measure the confounder more accurately. On the other hand, we have “selection bias” because controlling for the not measurement-invariant Covariate 1 opens a colliding path (X -&gt; Covariate 1 &lt;- True confound -&gt; Y; similar to model 16 in Cinelli, Forney, and Pearl (2024)). Because both biases are present, whenever some indicators are not measurement-invariant, the optimal control strategy would depend on the actual size of the path coefficients because we can construct edge cases, in which both biases cancel each other out:\n\nCodeR &lt;- 10000\nn &lt;- 200\nset.seed(42)\nsim3 &lt;- replicate(R, expr = {\n  true_confound &lt;- rnorm(n)\n  X &lt;- 0.5*true_confound + rnorm(n)\n  Y &lt;- 1*true_confound + 0.3*X + rnorm(n)\n  covariate1 &lt;- 1*true_confound + 0.5*X + rnorm(n) # cancel out both biases with 0.5*X\n  covariate2 &lt;- 2*true_confound + rnorm(n)\n  mod_ctrl_both &lt;- lm(Y ~ X + covariate1 + covariate2)\n  mod_ctrl_cov2 &lt;- lm(Y ~ X + covariate2)\n  c(est_ctrl_both = coef(mod_ctrl_both)[\"X\"],\n    est_ctrl_cov2 = coef(mod_ctrl_cov2)[\"X\"])})\n\nM_est_ctrl_both_sim3 &lt;- mean(sim3[\"est_ctrl_both.X\",])\nM_est_ctrl_cov2_sim3 &lt;- mean(sim3[\"est_ctrl_cov2.X\",])\nRMSE_ctrl_both_sim3 &lt;- sqrt(mean((sim3[\"est_ctrl_both.X\",] - 0.3)^2))\nRMSE_ctrl_cov2_sim3 &lt;- sqrt(mean((sim3[\"est_ctrl_cov2.X\",] - 0.3)^2))\n\n\nIn our example, if we set the problematic path (X -&gt; Covariate 1) to 0.5, the regression model controlling for both measures would estimate the causal effect of 0.3 almost perfectly (\\(M_{est} = 0.299\\)), but this would more or less be a coincidence. In a real application, we do not know the actual size of the path coefficients and can thus not determine whether including the non-invariant measure would be a good idea.\nTo sum up, I think a better recommendation would be something like:\n\nIf you have multiple measures of the same confounder, think hard about which measures might not be measurement-invariant (i.e., could be affected by the treatment or the outcome in your specific application), and include as many of the measurement-invariant ones in your regression model as possible.\n\nOf course, as also mentioned in JR’s post, we could always go one step further and try to test or specify violations of measurement invariance in a structural equation model (Sterner et al. 2024).\nIn closing, I want to stress that JR never claimed to provide general advice. I very much liked the original post (like most entries on The 100% CI blog) and I totally agree that traditional statistics education places a wrong emphasis on multicollinearity, while we should put a stronger focus on causal inference."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Florian Pargent",
    "section": "",
    "text": "I am a psychologist and statistician who teaches statistical methods, research methods, questionnaire development, and assessment to psychology students at LMU Munich. In my research, I try to introduce sophisticated statistical methods to psychological researchers and use these methods in applied work. I try my best to publish reproducible analysis code, provide or use open data, and convince my co-authors to publish preprints and choose journals with more sustainable open access policies.\nMy main research interests lie in the following areas:\n\n(Bayesian) Generative Modeling\n(Bayesian) Item Response Theory\n(Bayesian) Decision Theory\nPredictive Modeling and Machine Learning\nCausal Inference\nQuestionnaire Development\nResponse Styles in Questionnaires\nApplied Research"
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "Florian Pargent",
    "section": "",
    "text": "At the moment, I do not have a nicely formatted CV but only a collection of links where you can find some information on me and my work…\n\nYou can learn more about my academic background on Orcid and my webpage at LMU Munich.\nMy publications are listed on Google Scholar.\nI provide reproducible code and materials for my work and links to preprints on the OSF and Github.\nFor most courses I teach at LMU Munich, our group provides the materials as Open Educational Resources online (in German).\nI keep a list of my talks and workshops on the OSF."
  }
]